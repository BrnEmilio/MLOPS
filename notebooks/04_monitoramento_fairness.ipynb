{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 4: Monitoramento e Fairness em MLOps\n",
    "\n",
    "Nesta aula, vamos abordar:\n",
    "- O que é monitoramento em MLOps?\n",
    "- Por que fairness importa em modelos de Machine Learning?\n",
    "- Como implementar checagens simples de fairness e monitoramento em pipelines de ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Carregue modelo e vetorizador já treinados\n",
    "modelo_path = '../model.joblib'\n",
    "vetor_path = '../vectorizer.joblib'\n",
    "dados_path = '../data/tweets_limpo.csv'\n",
    "\n",
    "if not (os.path.exists(modelo_path) and os.path.exists(vetor_path)):\n",
    "    raise FileNotFoundError('Treine e salve o modelo antes de executar esta aula!')\n",
    "\n",
    "model = joblib.load(modelo_path)\n",
    "vectorizer = joblib.load(vetor_path)\n",
    "df = pd.read_csv(dados_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que é Monitoramento?\n",
    "\n",
    "Monitorar um modelo em produção significa:\n",
    "- Coletar informações sobre entradas e saídas do modelo\n",
    "- Detectar possíveis quebras de padrão (ex: nova distribuição dos dados)\n",
    "- Identificar quando o desempenho do modelo começa a cair\n",
    "\n",
    "Ferramentas comuns: **Evidently**, **Prometheus**, **logs simples** em arquivos ou dashboards.\n",
    "\n",
    "Vamos simular monitoramento básico de métricas e detectar deriva de dados!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simule recebimento de novos dados\n",
    "novos_textos = [\n",
    "    'Muito ruim, não gostei do atendimento.',\n",
    "    'A entrega foi sensacional!',\n",
    "    'Não funcionou, me decepcionei.',\n",
    "    'Recomendo para todos, nota 10!'\n",
    "]\n",
    "novos_df = pd.DataFrame({'text': novos_textos})\n",
    "\n",
    "# Vetorize e faça predições\n",
    "novos_vetores = vectorizer.transform(novos_df['text'])\n",
    "novos_preds = model.predict(novos_vetores)\n",
    "novos_df['sentimento_predito'] = novos_preds\n",
    "print(novos_df)\n",
    "\n",
    "# Monitoramento: porcentagem de cada classe\n",
    "class_dist = novos_df['sentimento_predito'].value_counts(normalize=True)\n",
    "print('Distribuição dos sentimentos preditos nos novos dados:')\n",
    "print(class_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que é Fairness?\n",
    "\n",
    "Fairness (equidade) significa que o modelo não deve apresentar vieses injustos contra determinados grupos, situações ou padrões.\n",
    "No contexto de textos, podemos analisar se o modelo está errando mais em frases curtas, ou se ele associa injustamente certas palavras a um sentimento.\n",
    "\n",
    "Vamos analisar fairness por tamanho de texto!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione coluna de tamanho dos textos\n",
    "df['text_len'] = df['text'].apply(len)\n",
    "df['len_category'] = pd.cut(df['text_len'], bins=[0,50,150,1000], labels=['curto', 'medio', 'longo'])\n",
    "\n",
    "# Predições no conjunto de validação\n",
    "vetores = vectorizer.transform(df['text'])\n",
    "df['pred'] = model.predict(vetores)\n",
    "\n",
    "# Análise de acurácia por categoria de tamanho\n",
    "for cat in df['len_category'].unique():\n",
    "    subset = df[df['len_category'] == cat]\n",
    "    if not subset.empty:\n",
    "        acuracia = (subset['label'] == subset['pred']).mean()\n",
    "        print(f'Acurácia para textos {cat}: {acuracia:.2f} (N={len(subset)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio Fairness\n",
    "\n",
    "- Analise o resultado das acurácias por tamanho de texto.\n",
    "- O modelo está menos justo com algum grupo? Por quê?\n",
    "- Sugira e teste melhorias (ex: aumentar dados de um grupo sub-representado).\n",
    "\n",
    "Extra: Que outras formas de fairness poderiam ser analisadas neste contexto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in df['len_category'].unique():\n",
    "    subset = df[df['len_category'] == cat]\n",
    "    if not subset.empty:\n",
    "        print(f'\\nMatriz de confusão para textos {cat}:')\n",
    "        print(confusion_matrix(subset['label'], subset['pred']))\n",
    "        sns.heatmap(confusion_matrix(subset['label'], subset['pred']),\n",
    "                    annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=['negativo', 'positivo'],\n",
    "                    yticklabels=['negativo', 'positivo'])\n",
    "        plt.title(f'Textos {cat}')\n",
    "        plt.xlabel('Predito')\n",
    "        plt.ylabel('Real')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}